# Alpaca Lora 4bit
Made some adjust for the code in peft and gptq for llama, and make it possible for lora finetuning with a 4 bits base model. The same adjustment can be made for 2, 3 and 8 bits.

___Note: Main branch would not be maintained anymore. Everyone should use the pip installable version. (winglian-setup_pip branch)___

* Install Manual:
```
git clone https://github.com/johnsmith0031/alpaca_lora_4bit.git
cd alpaca_lora_4bit
git fetch origin winglian-setup_pip
git checkout winglian-setup_pip
pip install .
```

* Active branch<br>
https://github.com/johnsmith0031/alpaca_lora_4bit/tree/winglian-setup_pip
