# Alpaca Lora 4bit
Made some adjust for the code in peft and gptq for llama, and make it possible for lora finetuning with a 4 bits base model. The same adjustment can be made for 2, 3 and 8 bits.

___Note: Main branch would not be maintained anymore. Everyone should use the pip installable version. (winglian-setup_pip branch)___

* pip installable version:
```
pip install git+https://github.com/johnsmith0031/alpaca_lora_4bit@winglian-setup_pip
```
